# Object Detection using [Mobilenetv2](https://github.com/tensorflow/models/tree/master/research/object_detection)

## Folder structure
```
.
├── Content
|   ├── model_tf
|       ├── community
|       ├── official
|       ├── research
|           ├── ...
|           ├── object_detection
|               ├── Training
|               ├── models
|               ├── protos
|               ├── data_tools
|               └── ...
|           └── ...
|       └── ...
└── Output
    ├── images
    └── video


```

The **Content file** contains tensorflow API will all necessary folder, packages and codes required for the implementation of various models such as mobilenet v1 and v2, fast rcnn  model, inception v2 and v3,etc. A breif overview on the necessary files it contains is shown below:
- It contains the image folder required for training and evaluation 
- Weights required to initiate the training 
- Scripts and instructions on annotating images
- Scripts and instructions on training a variety of models
- Utility scripts used by main scripts
- The configuration file of the model which is used to tune various parameters in the model like
   - The number of steps 
   - batch size
   - Training folder
   - learning rate
- The folder that saves checkpoints of the training
- Output folder that stores the results of the evalution
- The code for data preprocessing, training and evaluation. 

The **Output file** consists of a copy of the results obtained from the evaluation process. The results obtained is in the following format:
- image
- video


## Description of the model

The pretrained model use was obtained from [Tensorflow API](https://github.com/tensorflow/models/tree/master/research/object_detection). The model was trained on a kitchen [dataset](https://github.com/osman-95/Project_Progress_2/tree/master/Project_tasks/Mobilenet/models_Tf/research/object_detection/images) extracted from [indoor scene dataset](https://www.kaggle.com/itsahmad/indoor-scenes-cvpr-2019) from kaggle.The extracted dataset consisted of 300 images labelled with four labels
- oven
- kitchen sink
- refrigerator
- Range Hood

The data was labelled manually using [VoTT](https://github.com/microsoft/VoTT) software to label all the annotation of the images. The annotaion file generated by VoTT was in Pascal format (xml file) and was converted into csv format  using the [xml to csv](https://github.com/osman-95/Project_Progress_2/blob/master/Project_tasks/Mobilenet/models_Tf/research/object_detection/xml_to_csv.py ) code. This code convert the xml files to a csv list that is with tensorflow APU code structure. 

![]()

The data was trained with a pretrained weights to get better results and save training time. The weights were obtained from [Tensorflow models](https://github.com/osman-95/Project_Progress_2/blob/master/Project_tasks/Mobilenet/models_Tf/research/object_detection/g3doc/detection_model_zoo.md).

The data was trained for few hours until the loss value became very low and the results are shown below:
- [images](https://github.com/osman-95/Project_Progress_2/tree/master/Project_tasks/Mobilenet/)
- [video](https://github.com/osman-95/Project_Progress_2/tree/master/Project_tasks/Mobilenet/)

sample outputs

 ![](https://github.com/osman-95/Project_Progress_2/blob/master/Project_tasks/Mobilenet/Output/M_img2.png)
 
  ![](https://github.com/osman-95/Project_Progress_2/blob/master/Project_tasks/Mobilenet/Output/M_img.png)
  








