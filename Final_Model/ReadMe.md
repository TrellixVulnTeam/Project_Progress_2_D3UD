# Object detection-based Scene Classification

## Instructions

**Notice: all files are under progress and subjected to change**

- The Code file contains the code progress implemented upto 27th of July and is subjected to change

- The Dataset file contains the dataset generated before 16th of July and the is subjected to change

- The Trained model file contains the trained model for classification and object detection.

## Project Description

The main aim of the project is to design a real-time scene classification model to classify an image based on the objects detected in the image. The model is trained on all the possible combinations of objects that can appear in a frame/image to constitute a specific class (for example, if the objects detected in a frame/image are an oven, refrigerator, microwave and a sink, the model can determine the class of the image as kitchen).
The project can be divided into two parts,

- Detection of objects in an image
- Classification of the image based on the detected object

The object detection model is trained using a dataset of images of various indoor scenes (classes), with each having annotations/labels of various objects in the image. The dataset is trained with a pre-trained object detection model, Mobilenet v2. It was chosen for its high speed and fast training, which makes it suitable for real-time object detection.  

To classify an image based on the objects detected in a frame/image, the annotations generated for each frame by the object detector are trained on a classification model. The annotations generated by the images will be used to generate a tabular dataset containing all the information about the number of occurrences of each detected object and the class that it belongs to. The classification models that will be used are Feed-forward Neural network, K-Nearest Neighbors Classifier and Decision tree algorithm. Based on the accuracy and speed of the models, one model will be chosen for classification.

While testing the model, the annotations or labels detected by the object detection model are fed to the classification model to determine the class of the image.

![](https://github.com/osman-95/Project_Progress_2/blob/master/ReadMe_img/Model%20(3).jpg)

Before Elaborating the above sections, a quick overview on the file hierarchy of the main files are shown below
         
```   
         
└── Final_Model (Note: In progress last updated on 10th of july)
     └── Code
     └── Dataset
     └── Trained_models

 ```       

## Description of the dataset

In this project, the object detector was trained with a set of indoor scene images and the classification model was trained on a tabular CSV data containing the occurrence information of the detected object and their respective geometrical coordinate’s information.  

### Object Detection data description

The object detector was trained to detect  25 different indoor objects using a pre-trained coco mobilenetv2 model from [TensorFlow API]().  The 25 classes are listed below.
- Oven
- Refrigerator
- Sink
- Rangehood
- Bathtub
- Mirror
- Toilet seat
- Towel
- Bed
- Dresser cabinet
- Night table
- Table lamp
- Bowling ball
- Bowling pins
- Bowling rack
- Tv screen
- Dining table lamp
- Dining table
- Vase
- Chair	
- Computer
- Desk
- Keyboard
- Monitor
- Printer

Throughout the project, the model was trained on various image sets of indoor images 
- Dataset-1: 600 images of indoor scenes 
- Dataset-2: 1500 images of indoor scenes and objects
- Dataset-3: 2500 images of indoor scenes and objects

The dataset was created by MIT, and was obtained from [Kaggle](https://www.kaggle.com/itsahmad/indoor-scenes-cvpr-2019?). It consists of 67 categories/classes and a total of 15,620 images of a variety of indoor scenes such as classrooms, restaurants, bars, bakeries, bathrooms, libraries, bedrooms, airports, etc. The number of images in each category varies, but there are at least 100 images per category and all the images are in .jpg format. 

![Dataset](https://raw.githubusercontent.com/osman-95/Project_Prog/master/ReadMe_img/Capture1.PNG)

Only 6 classes were chosen to be worked on, with each containing 100 images. The decision to choose only 6 classes was made due to time constraints and hardware limitations. The 6 classes chosen were bedroom, bathroom, dining room, kitchen, bowling center, and office.

 ![Selected categories](https://github.com/osman-95/Project_Progress_2/blob/master/ReadMe_img/Capture12121.PNG)

I labelled the dataset manually using [VoTT software](https://github.com/microsoft/VoTT), with each class having at least 4 different types of annotations/labels. 

 ![](https://github.com/osman-95/Project_Progress_2/blob/master/ReadMe_img/Capture21211.PNG)
 
 ### Classification data description
 
 The classification dataset was built from the annotation CSV file of the Dataset 1 (600 images of indoor scenes). The dataset contains information about the occurrence of each object in an image and their geometrical coordinate’s information of these objects mapping it with their respective class as an output. Two datasets were built from the annotation CSV file: 
- Classification dataset 1- Contains the information about the occurrence of each object in an image
- Classification dataset 2- Contains the information about the occurrence of each object in an image in addition to their geometrical positional coordinates




